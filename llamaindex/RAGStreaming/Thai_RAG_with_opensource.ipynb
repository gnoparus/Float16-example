{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b3363b0-260f-4198-8de0-87cfa0828720",
   "metadata": {},
   "source": [
    "# หัวข้อ : สร้าง RAG สำหรับภาษาไทย ด้วย OpenSource \n",
    "\n",
    "#### จัดทำโดยทีม [VulturePrime](https://vultureprime.com) \n",
    "\n",
    "## รายละเอียด \n",
    "การสร้าง RAG เริ่มต้นเป็น Use case ที่แพร่หลายสำหรับการนำ AI เข้ามาประยุกต์ใช้กับธุรกิจ\n",
    "แต่เนื่องจากความขาดแคลนตัวอย่างที่เหมาะสมของแต่ละภาษา ทำให้เกิดปัญหา 2 ปัญหาได้แก่\n",
    "1. English centric ตัวอย่างส่วนใหญ่จะถูกทำขึ้นมาโดยใช้ภาษาอังกฤษเป็นศูนย์กลาง ทำให้ภาษาอื่นนั้น จำเป็นต้องประยุกต์ Solution ขึ้นมาเองซึ่งทำให้ Developer ต้องลงทุนในการเรียนรู้เพิ่มขึ้นอย่างมหาศาล ไม่ว่าจะเป็นในเรื่องของ Tokenizer หรือ Text splitter \n",
    "2. OpenAI centric เนื่องจากการเชื่อมต่อกับ OpenAI API นั้นเป็นเรื่องที่ใช้ Effort ต่ำสุดและมีประสิทธิภาพสูงที่สุด ทำให้ AI และ Embedding Model อื่นนั้น กลายเป็น 3rd class citizen เมื่อนักพัฒนาอยากลดรายจ่ายโดยใช้ AI และ Embedding รายอื่น จึงเป็นเรื่องที่มีต้นทุนสูงอย่างมหาศาล (Switching cost)  \n",
    "\n",
    "จากปัญหาทั้ง 2 ปัญหาทำให้เกิด AI Adoption ที่ช้ากว่าและแพงกว่าบริษัทที่ใช้ภาษาอังกฤษ​เป็นภาษาหลัก\n",
    "\n",
    "จึงเป็นที่มาของการสร้าง Use case ด้วยโปรเจคตัวอย่าง เพื่อให้ Developer สามารถลด Learning curve ลงไปได้\n",
    "และส่งเสริมให้มีความรวดเร็วในการนำ AI ไปใช้เพิ่มประสิทธิของ Feature ที่มีอยู่แล้วหรือสร้าง Feature ใหม่ขึ้นมา\n",
    "\n",
    "## บทความเพิ่มเติม (ภาษาไทย)\n",
    "- [Driving a Q&A Bot Project](https://www.vultureprime.com/blogs/driving-a-q-a-bot-project-a-product-owners-guide)\n",
    "\n",
    "## Benefit \n",
    "- ราคาต่อ Character ที่ถูกกว่า 90 - 95% เมื่อเทียบกับ OpenAI\n",
    "- เวลาในการประมวลผลที่น้อยลงเหลือเพียง 1/3 ถึง 1/4 (Float16 API หรือ SLA ตามต้องการ) \n",
    "- สามารถใช้งาน Offline หรือ Private เองได้\n",
    "\n",
    "## ความท้าทาย\n",
    "- การนับจำนวน Token ที่ไม่เท่ากันของภาษาอังกฤษและภาษาอื่น ทำให้ต้องสร้าง Custom Helper function เพื่อให้รองรับภาษาอื่น\n",
    "- การตัดประโยคของภาษาไทยเมื่อเทียบกับภาษาอื่น\n",
    "- การใช้งาน OpenSource เช่น Huggingface Embedding และ OpenAI API-like\n",
    "- การใช้งาน Vector Database และทำความเข้าใจ Parameter ในการค้นหา\n",
    "\n",
    "## Environment \n",
    "- [LlamaIndex](https://www.llamaindex.ai/) (Data Framework)\n",
    "- [Weaviate](https://weaviate.io/) (Vector Database)\n",
    "- [SeaLLM-7b](https://huggingface.co/SeaLLMs/SeaLLM-7B-Chat) (AI Model) ใช้งานผ่าน [Float16.cloud](https://float16.cloud)\n",
    "- [intfloat/multilingual-e5-large](https://huggingface.co/intfloat/multilingual-e5-large) (Embedding Model)\n",
    "\n",
    "## Flow \n",
    "1. บันทึกข้อมูลรูปแบบ String Text ไปยัง Vector Database\n",
    "2. ค้นหาข้อมูลจาก Vector Database และนำไปใช้กับ AI Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b20ba8-acba-475d-913c-d5ecfac38177",
   "metadata": {},
   "source": [
    "-------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7466ef30-3bfb-4eb9-9aee-295b0f3ef623",
   "metadata": {},
   "source": [
    "#### 1.เก็บข้อมูลรูปแบบ String Text ไปยัง Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa03704-cd15-41ee-befe-b8f6cabbc36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ทำการ Import Library ที่จำเป็น \n",
    "\n",
    "from llama_index import ServiceContext, StorageContext,VectorStoreIndex,Document\n",
    "from llama_index.embeddings import HuggingFaceEmbedding\n",
    "from llama_index.vector_stores import WeaviateVectorStore\n",
    "from llama_index.node_parser import TokenTextSplitter\n",
    "import weaviate \n",
    "\n",
    "#ทำการ Config API ที่ต้องการใช้\n",
    "FLOAT16_API_KEY = 'float16-XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'\n",
    "FLOAT16_CUSTOM_URL = 'https://api.float16.cloud/v1/llamaindex'\n",
    "WEAVIATE_ENDPOINT = \"https://XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\"\n",
    "\n",
    "#กำหนดชื่อ Embedding model ที่รองรับภาษาไทย\n",
    "embedding_model_name = \"intfloat/multilingual-e5-large\"\n",
    "\n",
    "#กำหนดชื่อ Document สำหรับ String Text ที่ต้องการบันทึกใน Vector Database\n",
    "document_name = 'FinOps_document_test1'\n",
    "\n",
    "#กำหนดชื่อสำหรับ text key สำหรับการค้นหา\n",
    "text_key = 'content'\n",
    "\n",
    "#Download Embedding Model จาก Huggingface\n",
    "embed_model = HuggingFaceEmbedding(model_name=embedding_model_name,max_length=1024)\n",
    "#เชื่อมต่อกับ Vector Database\n",
    "client = weaviate.Client(WEAVIATE_ENDPOINT)\n",
    "\n",
    "#สร้าง VectorStore Node\n",
    "vector_store = WeaviateVectorStore(weaviate_client = client,index_name = document_name,text_key = text_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f47246-ee07-41b9-b0a5-c99bfe7eb1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#String Text ที่ต้องการบันทึก อ้างอิงจากบทความ Cloud FinOps สำคัญต่อธุรกิจยุคดิจิทัลอย่างไร\n",
    "#https://www.vultureprime.com/blogs/how-important-is-cloud-finops-for-businesses-in-the-digital-era \n",
    "\n",
    "Finops_principle = \"\"\"II FinOps ?  \n",
    "A FinOps (cloud Financial Operations)\n",
    "FinOps Foundation เป็น Foundation ที่ได้รับการสนับสนุนจาก The Linux Foundation ในการช่วยสร้าง Foundation สำหรับการส่งเสริมและผลักดันการใช้งาน Cloud computing อย่างมีคุณค่า\n",
    "\n",
    "B History\n",
    "FinOps Foundation ก่อตั้งขึ้นมาตอน 2019 เกิดขึ้นหลังจากการมีอยู่ของ Cloud computing ประมาณ 10 ปี (AWS establish in 2006) ซึ่งถือว่าเป็น Foundation ที่มีอายุน้อยมาก (เทียบกับปี 2023) ฉะนั้นแล้วในส่วนของ Framework และ Best practice มีการอัพเดทอย่างรวดเร็วและเพิ่มขึ้นอย่างต่อเนื่อง เนื่องจาก use case ส่วนที่ยังไม่ได้ค้นพบยังมีอยู่มหาศาล\n",
    "III Cloud in real life  \n",
    "การใช้งาน Cloud นั้นเริ่มต้นนั้นจะดูเข้าใจง่าย แต่ความจริงแล้ววิธีคิดเงินของ Cloud นั้นมีความซับซ้อนและความเปลี่ยนแปลงสูง ซึ่งยังมีสิ่งที่ไม่เกี่ยวข้องกับวิธีคิดเงิน แต่เกี่ยวข้องกับความรับผิดชอบบางประการที่ถูกเปลี่ยนแปลงมาโดยไม่มีใครสังเกตุ\n",
    "A Spending decision\n",
    "ความรับผิดชอบด้านการจัดซื้อถูกย้ายมาให้กับทีม Engineer โดยตั้งใจหรือไม่ตั้งใจ ก็เป็นไปได้ทั้งสองกรณี โดยปกติแล้วการตัดสินใจในรายจ่ายเราจะมอบให้กับทีม Financial หรือทีม Procurement แต่เมื่อเป็น Cloud environment เรียบร้อยแล้ว คนที่เข้าใจ Cloud มากที่สุดกลับเป็นทีม Engineer ที่ไม่มีหน้าที่ในการรับผิดชอบการใช้จ่ายของบริษัท หรือเมื่อ Spending decision ยังอยู่กับทีม Financial คนที่ต้อง Commit รายจ่ายของ Cloud computing ก็ยังคงเป็นทีม Engineer\n",
    "\n",
    "ถ้าไม่แก้ไขปัญหาจากเหตุการณ์ดังกล่าวจะเกิดเหตุการณ์ Engineer Commit รายจ่ายให้สูงเกินความจำเป็น หรือ การใช้งานบางอย่าง (Serverless) ส่งผลให้เกิดรายจ่ายที่ผิดปกติในเดือนนั้น ๆ โดยไม่ทราบสาเหตุ\n",
    "\n",
    "วิธีแก้ไขของหลายบริษัทคือการให้ Engineer ลดรายจ่ายให้อยู่ในเพดานที่เหมาะสม\n",
    "\n",
    "อ่านดูแล้วอาจเป็นวิธีการแก้ปัญหาที่ตรงจุด แต่วิธีดังกล่าวกลับเหมาะสมกับบริบทดั้งเดิม ไม่สมเหตุสมผลกับบริบทปัจจุบัน เพราะการกระจายอำนาจตัดสินใจให้กับทีมอื่นได้นั้นถือเป็นความสามารถที่ไม่เคยเกิดขึ้นมาก่อนและยังสอดคล้องกับการทำงานยุคใหม่ที่ใช้ Framework อย่างเช่น Agile ที่ต้องการให้เกิดความรวดเร็วในการตัดสินใจ\n",
    "\n",
    "B Variable spending\n",
    "การใช้งานบางบริษัทของผู้ให้บริการ Cloud computing ไม่ได้คิดค่าบริการตามจำนวนชั่วโมงที่ใช้งานอย่างที่เราเข้าใจ แต่การคิดค่าบริการอาจคิดจากจำนวนการเรียกใช้งานหรือจำนวนของ bandwidth เป็นต้น\n",
    "\n",
    "ลักษณะการคิดค่าบริการดังกล่าวมีข้อดีคือเป็นการคิดค่าใช้จ่ายแบบ Variable cost เราสามารถนำไปใช้ในการคำนวณหา Cost Of Goods Sold (COGS) ได้ทันที\n",
    "\n",
    "ส่วนข้อเสียคือถ้าทีม Financial ไม่เข้าใจที่มาของต้นทุนดังกล่าวแล้วไม่ได้ลงไว้ใน Variable cost หรือ COGS จะเกิดคำถามว่าทำไมค่าใช้จ่าย Cloud computing ในแต่ละเดือนนั้น ไม่เท่ากันและไม่สามารถพิจารณาค่าใช้จ่าย Cloud computing ล่วงหน้า\n",
    "\n",
    "วิธีแก้ไขของหลายบริษัทคือไม่ใช้งาน Cloud computing ในส่วน Variable cost หรือไม่ต้องใช้งาน Cloud ไปเลย\n",
    "\n",
    "C Scalable resource\n",
    "การปรับจำนวนทรัพยากรได้ตลอดเวลานั้นสามารถส่งเสริมให้เกิดนวัตกรรมได้ตลอดเวลา เนื่องจากทีม Engineer สามารถเข้าถึงทรัพยากรได้อย่างรวดเร็วและเข้าถึงบางทรัพยากรที่ไม่เคยมีมาก่อน เช่น การเข้าถึง High performance computer, การเข้าถึง Computer cluster เป็นต้น สิ่งเหล่านี้จะทำให้ทีม Engineer สามารถทดลองนวัตกรรมใหม่ ๆ หรือสำรวจความเป็นไปได้ใหม่ ๆ โดยปราศจากข้อจำกัดด้านการจัดซื้อ\n",
    "\n",
    "แต่ข้อเสียที่เกิดขึ้นเมื่อทีม Engineer สามารถเข้าถึงทรัพยากรเหล่านี้ได้โดยปราศจากการอนุมัติจากทีม Finance บางครั้งทีม Engineer อาจจะลืมหรือละเลยการใช้งานทรัพยากรเหล่านี้โดยเปิดทิ้งไว้ตลอดเวลา แต่ใช้งานจริงแค่เพียง 1% ของเวลาที่คิดค่าใช้จ่าย  ทำให้เกิดค่าใช้จ่ายส่วนเกินที่ไม่ควรเกิดขึ้น\n",
    "\n",
    "ดังนั้นเพื่อเป็นการป้องกันปัญหาดังกล่าวจำเป็นต้องให้เกิดการตรวจสอบการใช้งานได้ตลอดเวลา เพื่อติดตามและป้องกันไม่ให้เกิดปัญหาดังกล่าว\n",
    "\n",
    "VII  FinOps framework ถูกสร้างขึ้นมาโดยมีหัวข้อหลักทั้งหมด 5 หัวข้อ ดังนี้\n",
    "Maturity\n",
    "Principles\n",
    "Personas\n",
    "Phases\n",
    "Domains\n",
    "โดยแต่ละหัวข้อจะอธิบายถึงสถานะ, เครื่องมือ, กิจกรรม, ความเข้ากันได้ หรือ สิ่งขับเคลื่อน ซึ่งแต่ละหัวข้อสามารถแยกพิจารณาเมื่อไหร่ก็ได้ ไม่จำเป็นต้องเรียงลำดับและในแต่ละบริษัทไม่จำที่จะต้องให้น้ำหนักกับแต่ละหัวข้อเหมือนกันทุกบริษัท ขึ้นอยู่กับบริบทของบริษัทนั้น ๆ\n",
    "\n",
    "เราขอเริ่มอธิบายจากหัวข้อแรก\n",
    "\n",
    "A Maturity\n",
    "Maturity เราอาจจะเรียกได้ว่าเป็นประสบการณ์ของทีม แต่ในที่นี้ขอเรียกว่าความเข้ากันได้ เนื่องจากบางบริษัททีมมีความเข้ากันได้อยู่แล้ว เคยทำงานร่วมกันด้วยความเข้าใจดีเยี่ยม ความเข้ากันได้ของทีมนั้น ๆ ก็จะสูงตาม\n",
    "\n",
    "ในบริบทของ FinOps เราแบ่ง Maturity ออกเป็น 3 ช่วง ได้แก่\n",
    "\n",
    "Crawl\n",
    "ช่วงแรกเริ่มของการนำ FinOps เข้ามาประยุกต์เข้ากับบริษัทของตัวเอง ซึ่งเราสามารถประเมินได้ว่าบริษัทที่อยู่ในช่วงดังกล่าวได้ว่า กระบวนการทำงาน, กระบวนการรายงานผล ยังอยู่ในรูปแบบของ Manual หรือไม่ได้ใช้ระบบอัตโนมัติเข้ามาช่วย รวมถึงการทำงานบางส่วน เช่น Forecast ค่าใช้จ่าย ยังคงต้องคำนวนใหม่ทุกครั้ง ยังไม่ได้สร้างสูตรหรือโมเดลในการช่วยคำนวน ต้องให้ทีม Finance ประเมินทุก ๆ คร้ัง\n",
    "\n",
    "Walk\n",
    "บางบริษัทอาจจะเริ่มจากช่วงนี้เลยก็เป็นไปได้ สำหรับช่วง walk นั้นจะเรียกได้ว่าเป็นช่วงของ Semi-Automate process เนื่องจากทีมมีบุคคลที่มีความสามารถในการสร้าง Automate process ด้วยตัวเอง ไม่ว่าจะเป็นทีม Engineer, ทีม Finance หรือทีม Finance ทำให้งานบางประเภทนั้นมีความสามารถในการทำงานอย่างอัตโนมัติ Automate process ที่สร้างขึ้นมานั้นสามารถให้คนที่ไม่มีความเชี่ยวชาญที่เกี่ยวข้องสามารถใช้งานได้โดยไม่มีผู้เชี่ยวชาญ\n",
    "\n",
    "Run\n",
    "“ทีมที่เพียบพร้อมด้วยสหวิทยาการ” นี่คือคำนิยามแบบเข้าใจง่ายของช่วงนี้ เพราะทีมที่มีความเข้ากันได้สูง สามารถสร้าง Automate process ออกมาได้ตรงประเด็น จำเป็นต้องมีความเข้าใจทั้งในส่วนที่ตัวเองเชี่ยวชาญและความเข้าใจในส่วนที่นอกเหนือจากที่ตัวเองเชี่ยวชาญ เพื่อที่จะสร้างระบบเพื่อส่งมอบข้อมูลเพื่อนำไปใช้ในการตัดสินได้ตลอดเวลา (Realtime) และช่วยให้บุคคลอื่นสามารถตัดสินใจบนข้อมูลได้อย่างทันท่วงที ไม่จำเป็นต้องปรึกษากับทีมอื่น\n",
    "\n",
    "B Principles\n",
    "Principles คือสิ่งที่ระบุถึงสิ่งที่จำเป็นต้องบรรลุเมื่อต้องการนำ FinOps เข้ามาใช้ในบริษัท ส่วนของ Principles นั้นจะมีความใกล้เคียงกับ Framework ที่เกี่ยวข้องกับ Digital transformation อย่างเช่น Agile หรือ DevOps เนื่องจากต้องการให้บริษัทไม่จำเป็นต้องปรับตัวทั้งหมดเพื่อที่จะเริ่มนำ FinOps ไปใช้งาน โดย Principles นั้นมีอยู่ทั้งหมด 6 ข้อได้แก่\n",
    "\n",
    "ทีมต้องทำงานร่วมกัน\n",
    "ทุกคนต้องเป็นเจ้าของการใช้งาน Cloud computing ร่วมกัน\n",
    "FinOps นั้นจะถูกขับเคลื่อนโดยทีมส่วนกลาง\n",
    "Report ที่เกี่ยวข้อง (Engineer, Finance, Business) ต้องเข้าถึงได้และทันท่วงที\n",
    "การตัดสินใจต้องถูกขับเคลื่อนโดยคุณค่าด้านธุรกิจผ่านการใช้งาน Cloud computing\n",
    "ใช้ความได้เปรียบด้าน Variable cost จาก Cloud computing\n",
    "C Personas\n",
    "Personas ในที่นี้จะระบุถึงแรงจูงใจ, ปัญหา, ตัวชี้วัดและสิ่งที่ได้จาก FinOps ซึ่ง Personas นั้นจะถูกแบ่งออกเป็น 5 บุคคลที่เกี่ยวข้องได้แก่\n",
    "\n",
    "1 FinOps Practitioner\n",
    "\n",
    "บุคคลผู้ซึ่งต้องการนำ FinOps เข้ามาใช้กับกระบวนการทำงานปัจจุบันของบริษัท โดยเป็นผู้ที่มีความเข้าใจใน Personas ของผู้อื่นมากที่สุด นิยามอย่างง่ายคือ ทีม Finance มองว่า (Practitioner) เป็นคนจากทีม Engineer แต่ทีม Engineer มองว่าเป็นคนจากทีม Fiannce\n",
    "\n",
    "2 Executive\n",
    "\n",
    "ผู้บริหารคืออีกหนึ่ง Personas ที่ต้องเข้ามามีส่วนเกี่ยวข้องในเงื่อนของการคาดหวังผลลัพธ์และต้องมีส่วนช่วยในการสนับสนุน (Sponsor) การเปลี่ยนแปลงดังกล่าวให้เกิดขึ้นให้ได้  \n",
    "\n",
    "3 Business\n",
    "\n",
    "ทีม Business หรือ Product owner ผู้ซึ่งต้องดูแลการเติบโตและวางเป้าหมายให้ตัวผลิตภัฑณ์หรือบริการที่กำลังดูแลอยู่นั้น ส่งมอบมูลค่าแก่ลูกค้าได้อย่างครบถ้วนและตรงจุด เป็นผู้ซึ่งเข้าใจในส่วนของ User หรือ Customer ได้ดีที่สุดจากทั้ง 5 บุคคลที่เกี่ยวข้อง\n",
    "\n",
    "4 Finance\n",
    "\n",
    "ทีม Finance เป็นทีมที่ดูแลเกี่ยวกับการลงทุนในแต่ละโปรเจคและต้องคอยประเมินถึงค่าใช้จ่ายระยะยาว โดยต้องประเมินถึงความคุ้มทุนของโปรเจคที่ต้องลงทุนและประเมินว่าเมื่อถึงเวลาใดจะเป็นจุด Break event point\n",
    "\n",
    "5 Engineer\n",
    "\n",
    "บุคคลที่เป็นคนตัดสินความเป็นไปได้ของการสร้างผลิตภัฑณ์หรือบริการ ซึ่งความเป็นไปได้สำหรับผลิตภัฑณ์หรือบริการทางด้าน software นั้น ตั้งอยู่บนพื้นฐาน 3 สิ่งคือ Quality, Cost และ Time สามารถเลือกได้แค่ 2 ใน 3 เท่านั้น\n",
    "\n",
    "D Phases\n",
    "Phase กล่าวคือวงวนกระบวนการสำหรับ FinOps โดยกระบวนการดังกล่าวนั้นสามารถเริ่มจากกระบวนการใดก็ได้ ไม่จำเป็นต้องเริ่มจาก Inform แต่จำเป็นต้องทำตามลำดับเช่น เริ่มจาก Optimize จากนั้นเรียงไป Operate และ Inform ตามลำดับ ซึ่งเมื่อเราสามารถวนครบรอบได้แล้ว เราสามารถทำต่อไปได้ไม่มีที่สิ้นสุด เนื่องจากทุก ๆ ครั้งในการครบรอบสิ่งที่ทีมจะได้เพิ่มคือความเข้ากันได้ของทีม (Maturity)\n",
    "\n",
    "Phase แบ่งออกด้วยกันทั้งหมด 3 phase ได้แก่\n",
    "\n",
    "1 Inform\n",
    "\n",
    "Phase inform จะเน้นผลลัพธ์ในการสร้างการเข้าถึงข้อมูล, การจัดการข้อมูล, การวัดผล, การกำหนดรายจ่าย และการ forecast รายจ่าย ในส่วนของ Inform จำเป็นต้องสร้างตัวชี้วัดโดยอาศัยข้อมูลจากทีมอื่นเข้ามาเป็นตัวแปรร่วมด้วย\n",
    "\n",
    "2 Optimize\n",
    "\n",
    "หลาย ๆ บริษัทมักอยากจะกระโดดเข้ามาใน Phase นี้เป็นส่วนแรก เนื่องจากเห็นผลได้รวดเร็วและมองเห็นถึงผลลัพธ์ได้ง่าย ในส่วนของ FinOps Foundation นั้นให้ความหมายของ Phase นี้เอาไว้ว่า เป็นช่วงที่ต้องมองหาความเป็นไปได้ในการลดต้นทุนและใช้ทรัพยากรที่มีอยู่ให้มีประสิทธิภาพสูงที่สุด หรือเข้าใจโดยง่ายว่า การ Optimize ทุกอย่างนั้นจะเกิดขึ้นแบบทฤษฎีก่อนนำไปให้ทีมที่เกี่ยวข้องนั้นนำไปใช้งานจริง\n",
    "\n",
    "3 Operate\n",
    "\n",
    "Phase นี้มักเป็นส่วนที่ถูกมองข้ามในการจำกัดความแต่ในการปฏิบัตินั้นเกิดขึ้นโดยไม่รู้ตัว ซึ่งการ Operate จะเป็นการเริ่มติดตามถึงตัวชี้วัดที่เราวางไว้, ติดตามถึงผลกระทบในส่วนของ Quality, Cost และ Time และในส่วนของการลงมือนำแผนการจาก Optimize นำไปใช้จริง\n",
    "\n",
    "E Domain\n",
    "Domain ระบุถึงกลุ่มกิจกรรมที่ให้ผลลัพธ์ออกมาในกลุ่มผลลัพธ์เดียวกัน โดย Domain นั้นจะถูกนำไปใช้ในแต่ Phase โดย Domain นั้นจะถูกกำหนดไว้ ณ ปัจจุบัน 6 Domain ได้แก่\n",
    "\n",
    "1 Understanding cloud usage and cost\n",
    "\n",
    "สำหรับ Domain นี้คือการรวมรวบข้อมูลที่เกี่ยวข้องกับการใช้งาน Cloud computing และนำข้อมูลที่ได้มานั้ดจัดให้อยู่ในรูปแบบที่สามารถเข้าถึงได้ ซึ่งข้อมูลดังกล่าวต้องตอบสนองต่อแต่ละ Personas อย่างครบถ้วน\n",
    "\n",
    "2 Performance Tracking & Benchmarking\n",
    "\n",
    "สำหรับการวัดผลและตั้งเป้าหมายจะถูกกำหนดขึ้น โดยเริ่มจากการตั้งงบประมาณ, การกำหนดผลลัพธ์ที่คาดหวัง หรือ ใช้ข้อมูลย้อนหลังเพื่อเป็นสมมติฐานการคำนวนรายจ่ายในอนาคต การวัดผลและการสร้างตัวชี้วัดทั้งหมดจะถูกสร้างใน Domain นี้\n",
    "\n",
    "3 Real-Time Decision Making\n",
    "\n",
    "การสร้างระบบสำหรับตัดสินใจแบบ Real time จะช่วยให้ผู้ที่มีส่วนได้ส่วนเสียทั้งหมดมีประสิทธิภาพในการรับมือกับสถานการณ์ต่าง ๆ ได้ดียิ่งขึ้น ไม่ว่าจะเป็นในด้านของเวลาในการตัดสินใจ หรือ คุณภาพในการตัดสินใจซึ่งต้องไปในทิศทางเดียวกันกับบริษัท\n",
    "\n",
    "4 Cloud Rate Optimization\n",
    "\n",
    "ภายใน Domain นี้จะกล่าวถึงการทำความเข้าใจเกี่ยวกับรูปแบบการคิดค่าบริการของผู้ให้บริการ Cloud computing และทำการปรับปรุงรายจ่าย Cloud computing ของบริษัทให้สอดคล้องกับรูปแบบการคิดค่าบริการของผู้ให้บริการ โดยคำนึงถึงข้อจำกัดที่แปรผันตามรูปแบบการคิดค่าบริการที่ต่างไป\n",
    "\n",
    "5 Cloud Usage Optimization\n",
    "\n",
    "Domain นี้ให้ความสำคัญถึงการใช้ทรัพยากรที่มีอยู่ให้คุ้มค่าที่สุด โดยการระบุและลงมือเปลี่ยนแปลงงานบางประเภทให้ประมวลผลให้ช่วงเวลาที่ Cloud computing นั้นไม่ได้ใช้งาน และรวมถึงการเปลี่ยนแปลงทรัพยากรที่มีอยู่ในเหมาะสมกับประเภทของงาน\n",
    "\n",
    "6 Organizational Alignment\n",
    "สำหรับ Domain นี้จะกล่าวถึงการที่บริษัทนั้นมีทิศทางในการใช้งาน Cloud computing ในทิศทางเดียวกันผ่าน Principles ของ FinOps ร่วมกัน เพื่อที่จะกำหนดวัฒนธรรมและนโยบายสำหรับบริษัทโดยไม่ขัดแย้งต่อวัฒนธรรมเดิมที่มีอยู่ของบริษัท\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25ed829-5e57-4eb1-acea-08300bf56912",
   "metadata": {},
   "outputs": [],
   "source": [
    "#กำหนดค่าของ Text Splitter ที่ต้องการใช้ \n",
    "#Chunk size กำหนดถึงความยาวของ Text ที่ต้องการตัด และ Chunk overlap หมายถึงการคาบเกี่ยวของ Text แต่ละชุดให้คาบเกี่ยวกับชุดก่อนหน้ามากน้อยแค่ไหน\n",
    "\n",
    "text_parser = TokenTextSplitter.from_defaults(chunk_overlap=256,chunk_size=1024)\n",
    "\n",
    "#ประมวลผล String Text ให้กลายเป็น List[String] โดย String มีขนาดตามที่กำหนดจากขั้นตอนก่อนหน้านี้\n",
    "nodes = text_parser.get_nodes_from_documents(\n",
    "    [Document(text=Finops_principle)], show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90e2206-f0ae-42c4-95ac-00b14b33e8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#กำหนดให้ใช้งาน Embedding ที่ทำการ Download มาจาก Huggingface\n",
    "service_context = ServiceContext.from_defaults(embed_model=embed_model,llm=None)\n",
    "#กำหนดให้ใช้งาน VectorDatabase ที่ทำการเชื่อมต่อกับ Weaviate\n",
    "storage_context = StorageContext.from_defaults(vector_store = vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd9a50a-6a69-4fb5-834a-f3e5775fec8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#นำ List[String] ที่ได้จากขั้นตอนประมวลผล Text นำมาแปลงให้อยู่ในรูปของ List[Vector] \n",
    "#แปลง String เป็น Vector โดยใช้ Embedding Model intfloat/multilingual-e5-large\n",
    "#หลังจากได้ List[Vector] และ List[String] ให้นำข้อมูลดังกล่าวเก็บไว้ยัง VectorDatabase ที่ได้เชื่อมต่อไว้แล้ว \n",
    "#โดยเก็บไว้ใน Document ชื่อ FinOps_document และมี Text_key เริ่มต้นด้วย \"content\"\n",
    "VectorStoreIndex(nodes=nodes,storage_context=storage_context, service_context = service_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362962d0-b817-4a59-aeef-083ec5963c0d",
   "metadata": {},
   "source": [
    "#### 2. ค้นหาข้อมูลจาก Vector Database และนำไปใช้กับ AI Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d230f3f3-b632-4974-9036-7b529d9bb894",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ทำการ Import Library ที่จำเป็น \n",
    "from llama_index.llms import openai_like\n",
    "from llama_index.readers.weaviate.reader import WeaviateReader\n",
    "from llama_index import ServiceContext, ListIndex\n",
    "from llama_index.embeddings import HuggingFaceEmbedding\n",
    "from llama_index.response_synthesizers import get_response_synthesizer\n",
    "from llama_index.llms import OpenAI\n",
    "from llama_index.indices.prompt_helper import PromptHelper\n",
    "import weaviate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6375705a-518d-4421-9cfe-bd9a2a6fb418",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ทำการ Config API ที่ต้องการใช้\n",
    "OPENAI_KEY = 'sk-XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'\n",
    "FLOAT16_API_KEY = 'float16-XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'\n",
    "FLOAT16_CUSTOM_URL = 'https://api.float16.cloud/v1/llamaindex'\n",
    "WEAVIATE_ENDPOINT = \"https://XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27500c47-0b1b-479a-8388-5c627850f4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ระบุ model ที่ต้องการใช้งาน \n",
    "#ณ​ วันที่ 5 มกราคม 2024 Float16 ยังคงรองรับแค่ seallm-7b เพียงตัวเลือกเดียว\n",
    "llm_model_name = \"seallm-7b-v2\"\n",
    "\n",
    "#กำหนดชื่อ Embedding model ที่รองรับภาษาไทย\n",
    "embedding_model_name = \"intfloat/multilingual-e5-large\"\n",
    "\n",
    "#กำหนดชื่อ Document สำหรับ String Text ที่ต้องการบันทึกใน Vector Database\n",
    "document_name = 'FinOps_document_test1'\n",
    "\n",
    "#กำหนดชื่อสำหรับ text key สำหรับการค้นหา\n",
    "text_key = 'content'\n",
    "\n",
    "#ระบุคำถามที่ต้องการถาม AI \n",
    "question = \"FinOps คืออะไร\"\n",
    "\n",
    "#Download Embedding Model จาก Huggingface\n",
    "embed_model = HuggingFaceEmbedding(model_name=embedding_model_name,max_length=1024)\n",
    "\n",
    "#เชื่อมต่อกับ Float16\n",
    "agent = openai_like.OpenAILike(\n",
    "    api_key=FLOAT16_API_KEY,\n",
    "    api_base=FLOAT16_CUSTOM_URL,\n",
    "    model=llm_model_name,\n",
    "    temperature=0.3,\n",
    "    max_tokens=512,\n",
    "    stream = True\n",
    ")\n",
    "\n",
    "#เชื่อมต่อกับ VectorDatabase\n",
    "client = weaviate.Client(WEAVIATE_ENDPOINT)\n",
    "reader = WeaviateReader(WEAVIATE_ENDPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfcf059-3b3b-4427-a05d-53e9a5dc4fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#สร้าง GraphQL query schema สำหรับการค้นหาข้อมูลที่เกี่ยวข้องจาก VectorDatabase\n",
    "query_schema = \"\"\" \n",
    "{{\n",
    "  Get{{\n",
    "    {document_name}(\n",
    "      nearVector: {{\n",
    "        vector: {vector_question},  \n",
    "        certainty: {certainty}\n",
    "      }}\n",
    "      limit : {limit}\n",
    "    ) {{\n",
    "      {text_key}\n",
    "    }}\n",
    "  }}\n",
    "}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dd6a73-968b-4c7b-bf35-6ecae0bd9ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#เปลี่ยนคำถาม (String) ให้กลายเป็น Vector\n",
    "vector_question = embed_model._embed(question)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e4eb71-bab7-4be2-83ca-2c3e19c87296",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ทำการ map ตัวแปรเข้ากับ Schema\n",
    "query = query_schema.format(\n",
    "  document_name=document_name,\n",
    "  vector_question=vector_question,\n",
    "  certainty=0.9,\n",
    "  text_key=text_key,\n",
    "  limit = 3\n",
    ")\n",
    "\n",
    "#ส่งคำสั่ง query ไปยัง VectorDatabase\n",
    "documents = reader.load_data(graphql_query=query, separate_documents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1e1571-2768-4c90-b808-9aa81aa0c9b3",
   "metadata": {},
   "source": [
    "#### กำหนด Service ที่เกี่ยวข้องกับ AI \n",
    "\n",
    "llm คือการกำหนดให้ใช้งาน LLM ตัวใดหรือผู้ให้บริการเจ้าใดสำหรับการรับ Prompt เพื่อให้ตอบคำถาม \n",
    "\n",
    "embed_model คือการกำหนดให้ใช้งาน Embedding ตัวใด สำหรับการแปลง Text ให้เป็น Vector \n",
    "\n",
    "prompt_helper คือตัวช่วยจิปาถะที่เกี่ยวข้องกับการใช้งาน LLM เช่น การทำให้ Prompt ที่ส่งไปยังผู้ให้บริการมีขนาดไม่เกินที่กำหนด (max_context) \n",
    "\n",
    "หรือ เมื่อ Prompt มีขนาดยาวเกินไปก็จะทำการ \"ตัดข้อมูล\" โดยอัตโนมัติ \n",
    "\n",
    "สำหรับ context_window ที่เรากำหนดขึ้นมานั้นมีขนาด 10,000 token ซึ่งการนับ Token โดย Default นั้น ใช้งาน Tiktoken หรือ OpenAI ในการนับ Token \n",
    "\n",
    "ทำให้ไม่สอดคล้องกับ SeaLLM-7b เนื่องจาก SeaLLM-7b นับ Token ต่างกับ OpenAI \n",
    "\n",
    "ส่งผลให้เมื่อใช้งาน context_window default จะทำให้ข้อมูลขาดหายไปบางช่วง \n",
    "\n",
    "DEFAULT context_window = 3900 #token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f365cf-9f49-415b-8c47-448c73f1b65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_context = ServiceContext.from_defaults(llm=agent,embed_model=embed_model,prompt_helper=PromptHelper(context_window=10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6738a7c-9dd9-4c33-8a2a-13f0ff83796f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#สร้าง index สำหรับการค้นหาข้อมูลจาก ผลลัพธ์จาก query\n",
    "index = ListIndex.from_documents(documents, service_context=service_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b69955-9f99-487c-acd2-214e15f19ac2",
   "metadata": {},
   "source": [
    "#### กำหนด Prompt pipeline สำหรับ RAG \n",
    "\n",
    "Default สำหรับ Llamaindex จะเป็นการ \"refine\" ซึ่ง refine จะเป็นขั้นตอนการทำงาน 2 ขั้นตอนต่อกัน\n",
    "1. Question and Answer เพื่อให้ LLM ที่กำหนดไว้ใน Service_context ตอบคำถาม\n",
    "2. Refine เพื่อให้คำตอบที่ได้ออกมานั้นสวยงามมากยิ่งขึ้น\n",
    "\n",
    "ทำให้เสียค่าใช้จ่ายในการ Query 2 ครั้ง\n",
    "\n",
    "ดังนั้นจึงเปลี่ยนเป็น \"simple_summarize\" จะลดขั้นตอนลงเหลือแค่ขั้นตอนเดียวนั้นคือ Question and Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989bce91-eaf7-4945-b813-77eb3fca99e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#กำหนด Prompt pipeline สำหรับ RAG \n",
    "response_synthesizer = get_response_synthesizer(\n",
    "      streaming=True,response_mode=\"simple_summarize\", service_context=service_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e089a97-92c8-40c6-9ec1-943ec8db15a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#สร้าง Query engine จาก index ที่เราได้สร้างจาก ผลลัพธ์จาก Query และเปลี่ยน Response ให้ทำงานแค่ 1 ขั้นตอน\n",
    "query_engine = index.as_query_engine(\n",
    "    streaming=True,\n",
    "    response_synthesizer=response_synthesizer,\n",
    "    service_context=service_context,\n",
    ")\n",
    "\n",
    "#ค้นหาผลลัพธ์จาก RAG\n",
    "result = query_engine.query(question)\n",
    "result.print_response_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef8c16e-ded5-4c0c-a459-4b4a01a1e91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #เปรียบเทียบผลลัพธ์กับ gpt-3.5-turbo เพื่อดูความแตกต่าง\n",
    "# openai_LLM = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.3, max_tokens=512,api_key=OPENAI_KEY)\n",
    "# openAI_service_context = ServiceContext.from_defaults(llm=openai_LLM,embed_model=embed_model)\n",
    "# response_synthesizer = get_response_synthesizer(\n",
    "#   response_mode=\"simple_summarize\", service_context=openAI_service_context\n",
    "# )\n",
    "# openai_query_engine = index.as_query_engine(\n",
    "#   response_synthesizer=response_synthesizer,\n",
    "#   service_context=openAI_service_context,\n",
    "# )\n",
    "# result = openai_query_engine.query(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f0f84c-1889-402a-8d84-c3da172786c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
